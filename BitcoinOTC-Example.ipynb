{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76e04ce",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05d94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss, GRUCell\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.nn import GCNConv, Linear\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03381bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import BitcoinOTC\n",
    "\n",
    "data = BitcoinOTC('bitcoinOTC/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3597e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROLANDGNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, num_nodes, dropout=0.0, update='moving', loss=BCEWithLogitsLoss):\n",
    "        \n",
    "        super(ROLANDGNN, self).__init__()\n",
    "        #Architecture: \n",
    "            #2 MLP layers to preprocess BERT repr, \n",
    "            #2 GCN layer to aggregate node embeddings\n",
    "            #HadamardMLP as link prediction decoder\n",
    "        \n",
    "        #You can change the layer dimensions but \n",
    "        #if you change the architecture you need to change the forward method too\n",
    "        #TODO: make the architecture parameterizable\n",
    "        \n",
    "        hidden_conv_1 = 64 \n",
    "        hidden_conv_2 = 32\n",
    "        self.preprocess1 = Linear(input_dim, 256)\n",
    "        self.preprocess2 = Linear(256, 128)\n",
    "        self.conv1 = GCNConv(128, hidden_conv_1)\n",
    "        self.conv2 = GCNConv(hidden_conv_1, hidden_conv_2)\n",
    "        self.postprocess1 = Linear(hidden_conv_2, 2)\n",
    "        \n",
    "        #Initialize the loss function to BCEWithLogitsLoss\n",
    "        self.loss_fn = loss()\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.update = update\n",
    "        if update=='moving':\n",
    "            self.tau = torch.Tensor([0])\n",
    "        elif update=='learnable':\n",
    "            self.tau = torch.nn.Parameter(torch.Tensor([0]))\n",
    "        elif update=='gru':\n",
    "            self.gru1 = GRUCell(hidden_conv_1, hidden_conv_1)\n",
    "            self.gru2 = GRUCell(hidden_conv_2, hidden_conv_2)\n",
    "        elif update=='mlp':\n",
    "            self.mlp1 = Linear(hidden_conv_1*2, hidden_conv_1)\n",
    "            self.mlp2 = Linear(hidden_conv_2*2, hidden_conv_2)\n",
    "        else:\n",
    "            assert(update>=0 and update <=1)\n",
    "            self.tau = torch.Tensor([update])\n",
    "        self.previous_embeddings = [torch.Tensor([[0 for i in range(hidden_conv_1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv_2)] for j in range(num_nodes)])]\n",
    "                                    \n",
    "        \n",
    "    def reset_loss(self,loss=BCEWithLogitsLoss):\n",
    "        self.loss_fn = loss()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.preprocess1.reset_parameters()\n",
    "        self.preprocess2.reset_parameters()\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "        self.postprocess1.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_label_index, previous_embeddings=None, num_current_edges=None, num_previous_edges=None):        \n",
    "        #You do not need all the parameters to be different to None in test phase\n",
    "        #You can just use the saved previous embeddings and tau\n",
    "        if previous_embeddings is not None: #None if test\n",
    "            self.previous_embeddings = [previous_embeddings[0].clone(),previous_embeddings[1].clone()]\n",
    "        if self.update=='moving' and num_current_edges is not None and num_previous_edges is not None: #None if test\n",
    "            #compute moving average parameter\n",
    "            self.tau = torch.Tensor([num_previous_edges / (num_previous_edges + num_current_edges)]).clone() # tau -- past weight\n",
    "        \n",
    "        current_embeddings = [torch.Tensor([]),torch.Tensor([])]\n",
    "        \n",
    "        #Preprocess text\n",
    "        h = self.preprocess1(x)\n",
    "        h = F.leaky_relu(h,inplace=True)\n",
    "        h = F.dropout(h, p=self.dropout,inplace=True)\n",
    "        h = self.preprocess2(h)\n",
    "        h = F.leaky_relu(h,inplace=True)\n",
    "        h = F.dropout(h, p=self.dropout, inplace=True)\n",
    "        \n",
    "        #GRAPHCONV\n",
    "        #GraphConv1\n",
    "        h = self.conv1(h, edge_index)\n",
    "        h = F.leaky_relu(h,inplace=True)\n",
    "        h = F.dropout(h, p=self.dropout,inplace=True)\n",
    "        #Embedding Update after first layer\n",
    "        if self.update=='gru':\n",
    "            h = torch.Tensor(self.gru1(h, self.previous_embeddings[0].clone()).detach().numpy())\n",
    "        elif self.update=='mlp':\n",
    "            hin = torch.cat((h,self.previous_embeddings[0].clone()),dim=1)\n",
    "            h = torch.Tensor(self.mlp1(hin).detach().numpy())\n",
    "        else:\n",
    "            h = torch.Tensor((self.tau * self.previous_embeddings[0].clone() + (1-self.tau) * h.clone()).detach().numpy())\n",
    "       \n",
    "        current_embeddings[0] = h.clone()\n",
    "        #GraphConv2\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = F.leaky_relu(h,inplace=True) # if inplace = True, it means it modify h directly\n",
    "        h = F.dropout(h, p=self.dropout,inplace=True)\n",
    "        #Embedding Update after second layer\n",
    "        if self.update=='gru':\n",
    "            h = torch.Tensor(self.gru2(h, self.previous_embeddings[1].clone()).detach().numpy())\n",
    "        elif self.update=='mlp':\n",
    "            hin = torch.cat((h,self.previous_embeddings[1].clone()),dim=1)\n",
    "            h = torch.Tensor(self.mlp2(hin).detach().numpy())\n",
    "        else:\n",
    "            h = torch.Tensor((self.tau * self.previous_embeddings[1].clone() + (1-self.tau) * h.clone()).detach().numpy())\n",
    "      \n",
    "        current_embeddings[1] = h.clone()\n",
    "        #HADAMARD MLP\n",
    "        h_src = h[edge_label_index[0]]\n",
    "        h_dst = h[edge_label_index[1]]\n",
    "        h_hadamard = torch.mul(h_src, h_dst) #hadamard product\n",
    "\n",
    "        h = self.postprocess1(h_hadamard)\n",
    "        h = torch.sum(h.clone(), dim=-1).clone()\n",
    "        \n",
    "        #return both \n",
    "        #i)the predictions for the current snapshot \n",
    "        #ii) the embeddings of current snapshot\n",
    "\n",
    "        return h, current_embeddings\n",
    "    \n",
    "    def loss(self, pred, link_label):\n",
    "        return self.loss_fn(pred, link_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c87220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def train_single_snapshot(model, data, train_data, val_data, test_data,\\\n",
    "                          last_embeddings, num_current_edges, num_previous_edges,\\\n",
    "                          optimizer, device='cpu', num_epochs=50, verbose=False):\n",
    "    avgpr_val_max = 0\n",
    "    best_model = model\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    best_current_embeddings = []\n",
    "    \n",
    "    tol = 5e-04\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        #pred = best_model(train_data)\n",
    "\n",
    "        pred,\\\n",
    "        current_embeddings =\\\n",
    "            model(train_data.x, train_data.edge_index, train_data.edge_label_index,\\\n",
    "                  last_embeddings, num_current_edges, num_previous_edges)\n",
    "        \n",
    "        loss = model.loss(pred, train_data.edge_label.type_as(pred)) #loss to fine tune on current snapshot\n",
    "\n",
    "        loss.backward(retain_graph=True)  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n MRR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_val = test(model, val_data, device)\n",
    "        \n",
    "        if avgpr_val_max-tol <= avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_current_embeddings = current_embeddings\n",
    "            best_model = model\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        \n",
    "    avgpr_score_train = test(model, train_data, device)\n",
    "    avgpr_score_test = test(model, test_data, device)\n",
    "    \n",
    "    return best_model, optimizer, avgpr_score_train, avgpr_score_test, best_current_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca9a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, device):\n",
    "    model.eval()\n",
    "\n",
    "    test_data = test_data.to(device)\n",
    "\n",
    "    h, _ = model(test_data.x, test_data.edge_index, test_data.edge_label_index)\n",
    "    \n",
    "    pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    \n",
    "    label = test_data.edge_label.cpu().detach().numpy()\n",
    "      \n",
    "    avgpr_score = average_precision_score(label, pred_cont)\n",
    "    \n",
    "    return avgpr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb5506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_roland(model, snapshots, hidden_conv1, hidden_conv2, optimizer, device='cpu'):\n",
    "    num_snap = len(snapshots)\n",
    "    num_previous_edges = 0\n",
    "    last_embeddings = [torch.Tensor([[0 for i in range(hidden_conv1)] for j in range(num_nodes)]),\\\n",
    "                                    torch.Tensor([[0 for i in range(hidden_conv2)] for j in range(num_nodes)])]\n",
    "    avgpr_train_singles = []\n",
    "    avgpr_test_singles = []\n",
    "    for i in range(num_snap-1):\n",
    "        #CREATE TRAIN + VAL + TEST SET FOR THE CURRENT SNAP\n",
    "        snapshot = copy.deepcopy(snapshots[i])\n",
    "        snapshot.x = torch.Tensor([[1] for i in range(snapshot.num_nodes)])\n",
    "        num_current_edges = len(snapshot.edge_index[0])\n",
    "        transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "        train_data, _, val_data = transform(snapshot)\n",
    "        if i == 0:\n",
    "            print(\"num_current_edges\", num_current_edges)\n",
    "            print(\"train data is of size\", train_data, \"val data is of size\", val_data)\n",
    "        test_data = copy.deepcopy(snapshots[i+1])\n",
    "        test_data.x = torch.Tensor([[1] for i in range(test_data.num_nodes)])\n",
    "        future_neg_edge_index = negative_sampling(\n",
    "            edge_index=test_data.edge_index, #positive edges\n",
    "            num_nodes=test_data.num_nodes, # number of nodes\n",
    "            num_neg_samples=test_data.edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
    "        #edge index ok, edge_label concat, edge_label_index concat\n",
    "        num_pos_edge = test_data.edge_index.size(1)\n",
    "        test_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_pos_edge)]))\n",
    "        test_data.edge_label_index = torch.cat([test_data.edge_index, future_neg_edge_index], dim=-1)\n",
    "        \n",
    "        #TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\n",
    "        model, optimizer, avgpr_train, avgpr_test, last_embeddings =\\\n",
    "            train_single_snapshot(model, snapshot, train_data, val_data, test_data,\\\n",
    "                                  last_embeddings, num_current_edges, num_previous_edges,\\\n",
    "                                  optimizer)\n",
    "        \n",
    "        #SAVE AND DISPLAY EVALUATION\n",
    "        print(f'Snapshot: {i}\\n AVGPR Train: {avgpr_train}, Test: {avgpr_test}\\n')\n",
    "        avgpr_train_singles.append(avgpr_train)\n",
    "        avgpr_test_singles.append(avgpr_test)\n",
    "        \n",
    "        #COMPUTE NEW NUMBER OF EDGES\n",
    "        num_previous_edges = num_previous_edges + num_current_edges\n",
    "        \n",
    "    avgpr_train_all = sum(avgpr_train_singles)/len(avgpr_train_singles)\n",
    "    avgpr_test_all = sum(avgpr_test_singles)/len(avgpr_test_singles)\n",
    "    \n",
    "    print(f'AVGPR over time: Train {avgpr_train_all}, Test: {avgpr_test_all}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ebbaa52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7251e00a6dd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd84cad",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f8006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = data[0].num_node_features\n",
    "hidden_conv1 = 64\n",
    "hidden_conv2 = 32\n",
    "num_classes = 2\n",
    "num_nodes = data[0].num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bed96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ROLANDGNN(input_dim, num_nodes, update='gru')\n",
    "model.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfebad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 5e-3\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=weight_decay)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01, weight_decay = weight_decay)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=0.1, weight_decay = weight_decay)\n",
    "#optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "548dd312",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_current_edges 41\n",
      "train data is of size Data(edge_index=[2, 31], edge_attr=[31], num_nodes=6005, x=[6005, 1], edge_label=[62], edge_label_index=[2, 62]) val data is of size Data(edge_index=[2, 31], edge_attr=[31], num_nodes=6005, x=[6005, 1], edge_label=[20], edge_label_index=[2, 20])\n",
      "Snapshot: 0\n",
      " AVGPR Train: 0.8083954266947113, Test: 0.7661058619796044\n",
      "\n",
      "Snapshot: 1\n",
      " AVGPR Train: 0.9624371745602568, Test: 0.8159440285762837\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_roland\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_conv1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_conv2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m, in \u001b[0;36mtrain_roland\u001b[0;34m(model, snapshots, hidden_conv1, hidden_conv2, optimizer, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m test_data\u001b[38;5;241m.\u001b[39medge_label_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([test_data\u001b[38;5;241m.\u001b[39medge_index, future_neg_edge_index], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#TRAIN AND TEST THE MODEL FOR THE CURRENT SNAP\u001b[39;00m\n\u001b[1;32m     30\u001b[0m model, optimizer, avgpr_train, avgpr_test, last_embeddings \u001b[38;5;241m=\u001b[39m\\\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mtrain_single_snapshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mlast_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_current_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_previous_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#SAVE AND DISPLAY EVALUATION\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSnapshot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m AVGPR Train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavgpr_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavgpr_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m, in \u001b[0;36mtrain_single_snapshot\u001b[0;34m(model, data, train_data, val_data, test_data, last_embeddings, num_current_edges, num_previous_edges, optimizer, device, num_epochs, verbose)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#pred = best_model(train_data)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m pred,\\\n\u001b[1;32m     25\u001b[0m current_embeddings \u001b[38;5;241m=\u001b[39m\\\n\u001b[1;32m     26\u001b[0m     model(train_data\u001b[38;5;241m.\u001b[39mx, train_data\u001b[38;5;241m.\u001b[39medge_index, train_data\u001b[38;5;241m.\u001b[39medge_label_index,\\\n\u001b[1;32m     27\u001b[0m           last_embeddings, num_current_edges, num_previous_edges)\n\u001b[0;32m---> 29\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#loss to fine tune on current snapshot\u001b[39;00m\n\u001b[1;32m     31\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Derive gradients.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update parameters based on gradients.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 117\u001b[0m, in \u001b[0;36mROLANDGNN.loss\u001b[0;34m(self, pred, link_label)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, pred, link_label):\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_label\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:731\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:3226\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m   3224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/fx/traceback.py:67\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_list(\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/usr/lib/python3.10/traceback.py:227\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[0;32m--> 227\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[0;32m/usr/lib/python3.10/traceback.py:376\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[0;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m         f_locals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFrameSummary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlineno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_line\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_locals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m    379\u001b[0m     linecache\u001b[38;5;241m.\u001b[39mcheckcache(filename)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_roland(model, data, hidden_conv1, hidden_conv2, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
