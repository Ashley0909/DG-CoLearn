{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing global embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque, defaultdict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_embedding_update_sum(start_node, ccn, k):\n",
    "    embeddings_required = []\n",
    "    dq = deque([(start_node, k, {start_node})])\n",
    "    while dq:\n",
    "        node, hop, nodes_visited = dq.popleft()\n",
    "        embeddings_required.append([node, hop])\n",
    "        if hop > 1 and node == start_node:\n",
    "            embeddings_required += [[node, 0]]  * len(ccn[node]) # count the times 1-hop ccn visits itself\n",
    "        elif hop > 1:\n",
    "            embeddings_required += [[node, 0]] # add 0-hop whenever it is visited\n",
    "\n",
    "        for neigh in ccn[node]:\n",
    "            if neigh not in nodes_visited and hop>0:\n",
    "                dq.append((neigh, hop-1, nodes_visited|{neigh}))\n",
    "\n",
    "    return embeddings_required\n",
    "\n",
    "def get_global_embedding(embeddings, ccn, node_client_map):\n",
    "    hop_embeddings = []\n",
    "    for hop in range(3):\n",
    "        hop_matrix = []\n",
    "        for node in range(len(node_client_map)):\n",
    "            node_embdedding_sum = node_embedding_update_sum(node, ccn, hop)\n",
    "            final_embedding = torch.zeros(embeddings[0][0][0].shape)\n",
    "            for update_node, k in node_embdedding_sum:\n",
    "                final_embedding += embeddings[node_client_map[update_node]][k][update_node]\n",
    "            hop_matrix.append(final_embedding)\n",
    "        hop_embeddings.append(hop_matrix)\n",
    "\n",
    "    return hop_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create test graph 1'''\n",
    "ccn_1 = defaultdict(list)\n",
    "ccn_1[3].append(4)\n",
    "ccn_1[4].append(3)\n",
    "\n",
    "node_assignment_1 = [0,0,0,0,1,1,1,1]\n",
    "embeddings_1 = torch.tensor([[[[1,1],[2,2],[3,3],[4,4],[0,0],[0,0],[0,0],[0,0]],\n",
    "                 [[2,2],[4,4],[6,6],[8,8],[0,0],[0,0],[0,0],[0,0]],\n",
    "                 [[3,3],[5,5],[7,7],[9,9],[0,0],[0,0],[0,0],[0,0]]],\n",
    "                [[[0,0],[0,0],[0,0],[0,0],[1,1],[2,2],[3,3],[4,4]],\n",
    "                [[0,0],[0,0],[0,0],[0,0],[2,2],[4,4],[6,6],[8,8]],\n",
    "                [[0,0],[0,0],[0,0],[0,0],[3,3],[5,5],[7,7],[9,9]]]])\n",
    "\n",
    "# node_embedding_update_sum(4, ccn_1, 0)\n",
    "# get_global_embedding(embeddings_1, ccn_1, node_assignment_1)\n",
    "\n",
    "# '''Create test graph 2'''\n",
    "# ccn_2 = defaultdict(list)\n",
    "# ccn_2[3].append(4)\n",
    "# ccn_2[4].append(3)\n",
    "# ccn_2[3].append(8)\n",
    "# ccn_2[8].append(3)\n",
    "# node_assignment_2 = [0,0,0,0,1,1,1,1,2,2,2]\n",
    "# embeddings_1 = torch.tensor([[[[1,1],[2,2],[3,3],[4,4],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0]],\n",
    "#                  [[2,2],[4,4],[6,6],[8,8],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0]],\n",
    "#                  [[3,3],[5,5],[7,7],[9,9],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0]]],\n",
    "\n",
    "#                 [[[0,0],[0,0],[0,0],[0,0],[1,1],[2,2],[3,3],[4,4],[0,0],[0,0],[0,0]],\n",
    "#                 [[0,0],[0,0],[0,0],[0,0],[2,2],[4,4],[6,6],[8,8],[0,0],[0,0],[0,0]],\n",
    "#                 [[0,0],[0,0],[0,0],[0,0],[3,3],[5,5],[7,7],[9,9],[0,0],[0,0],[0,0]]],\n",
    "\n",
    "#                 [[[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[1,1],[2,2],[3,3]],\n",
    "#                 [[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[2,2],[4,4],[6,6]],\n",
    "#                 [[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[3,3],[5,5],[7,7]]],\n",
    "#                 ])\n",
    "\n",
    "# node_embedding_update_sum(3, ccn_2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {3: [4], 4: [3]})\n"
     ]
    }
   ],
   "source": [
    "print(ccn_1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
